{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7271f70c",
   "metadata": {},
   "source": [
    "# Audiobook Generator (XTTS v2 voice cloning) — Notebook\n",
    "\n",
    "This notebook generates an audiobook-style audio file from a **TXT** file using a **reference voice sample** (**MP3**) for speaker conditioning (voice cloning) via **Coqui TTS (XTTS v2)**.\n",
    "\n",
    "**Folder assumption:** the reference voice MP3 and the input TXT are in the **same folder** as this notebook (or you can point to a different folder).\n",
    "\n",
    "**Ethics/safety:** Only clone a voice you own or have **explicit permission** to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01967198",
   "metadata": {},
   "source": [
    "## 1) Install dependencies\n",
    "\n",
    "- `TTS` for XTTS v2\n",
    "- `pydub` for audio conversion/concatenation\n",
    "- `ffmpeg` is required for MP3 I/O, speed control, loudness normalization, and silence trimming.\n",
    "\n",
    "### Known dependency issue (BeamSearchScorer)\n",
    "If you see: `ImportError: cannot import name 'BeamSearchScorer' from 'transformers'`\n",
    "pin Transformers to `<4.57`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09752426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python packages (run once per environment)\n",
    "# Pin transformers to avoid BeamSearchScorer import break in transformers>=4.57\n",
    "%pip install -q --upgrade \"TTS\" \"transformers<4.57\" \"pydub\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27291506",
   "metadata": {},
   "source": [
    "## 2) Set inputs/outputs\n",
    "\n",
    "- **VOICE_MP3**: reference voice sample in MP3 format (10–30s clean speech recommended)\n",
    "- **TEXT_TXT**: input text file in TXT format\n",
    "- **OUT_AUDIO**: output audiobook file (.wav or .mp3). MP3 requires FFmpeg.\n",
    "\n",
    "### Output tuning\n",
    "- **SPEED**: tempo change *without* pitch shift (FFmpeg `atempo`)\n",
    "- **MP3_BITRATE**: used only for MP3 output\n",
    "- **NORMALIZE_LOUDNESS**: applies EBU R128-style loudness normalization (FFmpeg `loudnorm`)\n",
    "- **TRIM_SILENCE**: trims leading/trailing silence (FFmpeg `silenceremove`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b56f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# If files are in the same folder as this notebook, keep WORKDIR as '.'\n",
    "WORKDIR = Path(\".\")\n",
    "\n",
    "VOICE_MP3 = WORKDIR / \"voice_sample.mp3\"   # <-- change filename\n",
    "TEXT_TXT   = WORKDIR / \"book.txt\"          # <-- change filename\n",
    "\n",
    "OUT_AUDIO  = WORKDIR / \"audiobook.mp3\"     # can be .wav or .mp3\n",
    "\n",
    "# TTS options\n",
    "LANG = \"en\"          # e.g., 'en', 'vi', 'zh-cn'\n",
    "USE_GPU = False      # set True if you have CUDA GPU properly set up\n",
    "MAX_CHARS_PER_CHUNK = 260\n",
    "\n",
    "# Output tuning\n",
    "SPEED = 1.0                 # 1.0 = normal, 1.1 = 10% faster, 0.9 = 10% slower\n",
    "MP3_BITRATE = \"192k\"        # e.g. \"96k\", \"128k\", \"192k\", \"256k\"\n",
    "\n",
    "NORMALIZE_LOUDNESS = True   # loudnorm\n",
    "LOUDNORM_I = -16            # Integrated loudness target (LUFS). Common: -16 (podcast/audiobook)\n",
    "LOUDNORM_TP = -1.5          # True peak (dBTP)\n",
    "LOUDNORM_LRA = 11           # Loudness range\n",
    "\n",
    "TRIM_SILENCE = True         # silenceremove\n",
    "SILENCE_THRESHOLD_DB = -45  # threshold in dB for silence detection\n",
    "SILENCE_MIN_SEC = 0.20      # min silence duration to trim at start/end (seconds)\n",
    "\n",
    "VOICE_MP3, TEXT_TXT, OUT_AUDIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eae3df",
   "metadata": {},
   "source": [
    "## 3) Imports and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817eec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def assert_exists(path: Path, label: str):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"{label} not found: {path.resolve()}\")\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    # Remove hyphenation at line breaks: \"exam-\\nple\" -> \"example\"\n",
    "    text = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", text)\n",
    "    # Collapse whitespace\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def split_into_chunks(text: str, max_chars: int = 260) -> list[str]:\n",
    "    \"\"\"Sentence-ish split then repack into chunks up to max_chars.\"\"\"\n",
    "    sentences = re.split(r\"(?<=[.!?。！？])\\s+\", text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    chunks = []\n",
    "    buf = \"\"\n",
    "    for s in sentences:\n",
    "        # If a single sentence is huge, hard-split it.\n",
    "        if len(s) > max_chars:\n",
    "            if buf:\n",
    "                chunks.append(buf.strip())\n",
    "                buf = \"\"\n",
    "            for i in range(0, len(s), max_chars):\n",
    "                chunks.append(s[i:i+max_chars].strip())\n",
    "            continue\n",
    "\n",
    "        if not buf:\n",
    "            buf = s\n",
    "        elif len(buf) + 1 + len(s) <= max_chars:\n",
    "            buf += \" \" + s\n",
    "        else:\n",
    "            chunks.append(buf.strip())\n",
    "            buf = s\n",
    "\n",
    "    if buf:\n",
    "        chunks.append(buf.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def mp3_to_wav(mp3_path: Path, wav_path: Path) -> Path:\n",
    "    \"\"\"Convert MP3 -> WAV using pydub (requires ffmpeg).\"\"\"\n",
    "    audio = AudioSegment.from_file(mp3_path, format=\"mp3\")\n",
    "    audio = audio.set_channels(1)  # mono often works better for speaker conditioning\n",
    "    audio.export(wav_path, format=\"wav\")\n",
    "    return wav_path\n",
    "\n",
    "def _atempo_chain(speed: float) -> str:\n",
    "    \"\"\"Build chained atempo filters to support speeds outside 0.5..2.0.\"\"\"\n",
    "    if speed <= 0:\n",
    "        raise ValueError(\"SPEED must be > 0\")\n",
    "\n",
    "    parts = []\n",
    "    x = float(speed)\n",
    "\n",
    "    while x > 2.0:\n",
    "        parts.append(\"atempo=2.0\")\n",
    "        x /= 2.0\n",
    "    while x < 0.5:\n",
    "        parts.append(\"atempo=0.5\")\n",
    "        x /= 0.5\n",
    "\n",
    "    parts.append(f\"atempo={x:.6f}\".rstrip(\"0\").rstrip(\".\"))\n",
    "    return \",\".join(parts)\n",
    "\n",
    "def _silenceremove_filter(threshold_db: float, min_sec: float) -> str:\n",
    "    \"\"\"Trim leading+trailing silence using silenceremove.\"\"\"\n",
    "    thr = f\"{threshold_db}dB\"\n",
    "    d = max(0.0, float(min_sec))\n",
    "    return (\n",
    "        f\"silenceremove=\"\n",
    "        f\"start_periods=1:start_duration={d}:start_threshold={thr}:\"\n",
    "        f\"stop_periods=1:stop_duration={d}:stop_threshold={thr}\"\n",
    "    )\n",
    "\n",
    "def _loudnorm_filter(I: float, TP: float, LRA: float) -> str:\n",
    "    \"\"\"EBU R128 loudness normalization (single-pass).\"\"\"\n",
    "    return f\"loudnorm=I={I}:TP={TP}:LRA={LRA}\"\n",
    "\n",
    "def export_with_ffmpeg_filters(\n",
    "    audio: AudioSegment,\n",
    "    out_path: Path,\n",
    "    speed: float = 1.0,\n",
    "    mp3_bitrate: str = \"192k\",\n",
    "    trim_silence: bool = True,\n",
    "    silence_threshold_db: float = -45,\n",
    "    silence_min_sec: float = 0.20,\n",
    "    normalize_loudness: bool = True,\n",
    "    loudnorm_I: float = -16,\n",
    "    loudnorm_TP: float = -1.5,\n",
    "    loudnorm_LRA: float = 11,\n",
    "):\n",
    "    \"\"\"Export AudioSegment applying FFmpeg filters: silenceremove, atempo, loudnorm, and bitrate.\"\"\"\n",
    "    if shutil.which(\"ffmpeg\") is None:\n",
    "        raise RuntimeError(\"ffmpeg not found on PATH. Install ffmpeg to use MP3 I/O and audio filtering.\")\n",
    "\n",
    "    out_path = Path(out_path)\n",
    "    out_ext = out_path.suffix.lower()\n",
    "\n",
    "    # Write a temp WAV from pydub, then let FFmpeg filter+encode.\n",
    "    tmp_wav = out_path.with_suffix(\".tmp_export.wav\")\n",
    "    audio.export(tmp_wav, format=\"wav\")\n",
    "\n",
    "    filters = []\n",
    "    if trim_silence:\n",
    "        filters.append(_silenceremove_filter(silence_threshold_db, silence_min_sec))\n",
    "    if abs(speed - 1.0) > 1e-6:\n",
    "        filters.append(_atempo_chain(speed))\n",
    "    if normalize_loudness:\n",
    "        filters.append(_loudnorm_filter(loudnorm_I, loudnorm_TP, loudnorm_LRA))\n",
    "\n",
    "    cmd = [\"ffmpeg\", \"-y\", \"-i\", str(tmp_wav)]\n",
    "\n",
    "    if filters:\n",
    "        cmd += [\"-filter:a\", \",\".join(filters)]\n",
    "\n",
    "    if out_ext == \".mp3\":\n",
    "        cmd += [\"-b:a\", mp3_bitrate, str(out_path)]\n",
    "    elif out_ext == \".wav\":\n",
    "        cmd += [\"-c:a\", \"pcm_s16le\", str(out_path)]\n",
    "    else:\n",
    "        raise ValueError(\"OUT_AUDIO must end with .wav or .mp3\")\n",
    "\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    try:\n",
    "        tmp_wav.unlink()\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54ce88",
   "metadata": {},
   "source": [
    "## 4) Load input files + convert voice MP3 → WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f880bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_exists(VOICE_MP3, \"Reference voice MP3\")\n",
    "assert_exists(TEXT_TXT, \"Input TXT\")\n",
    "\n",
    "voice_wav = VOICE_MP3.with_suffix(\".wav\")\n",
    "if not voice_wav.exists():\n",
    "    print(f\"Converting {VOICE_MP3.name} -> {voice_wav.name}\")\n",
    "    mp3_to_wav(VOICE_MP3, voice_wav)\n",
    "else:\n",
    "    print(f\"Using existing WAV: {voice_wav.name}\")\n",
    "\n",
    "voice_wav\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d9470",
   "metadata": {},
   "source": [
    "## 5) Read text and chunk it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d340698",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = TEXT_TXT.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "text = normalize_text(raw_text)\n",
    "\n",
    "if not text:\n",
    "    raise RuntimeError(\"No text found in the TXT file.\")\n",
    "\n",
    "chunks = split_into_chunks(text, max_chars=MAX_CHARS_PER_CHUNK)\n",
    "\n",
    "print(f\"Characters: {len(text):,}\")\n",
    "print(f\"Chunks: {len(chunks):,} (max {MAX_CHARS_PER_CHUNK} chars each)\")\n",
    "\n",
    "# Preview first chunk\n",
    "chunks[0][:500]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37772d0e",
   "metadata": {},
   "source": [
    "## 6) Load XTTS v2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4457590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "MODEL_NAME = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME} (gpu={USE_GPU})\")\n",
    "tts = TTS(model_name=MODEL_NAME, gpu=USE_GPU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb5643",
   "metadata": {},
   "source": [
    "## 7) Generate audio chunks and concatenate into a single audiobook\n",
    "\n",
    "This will create a folder like `audiobook_chunks/` next to your output file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc12ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory for chunk WAVs\n",
    "chunk_dir = OUT_AUDIO.parent / f\"{OUT_AUDIO.stem}_chunks\"\n",
    "chunk_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chunk_files = []\n",
    "total = len(chunks)\n",
    "\n",
    "for i, chunk in enumerate(chunks, start=1):\n",
    "    chunk_file = chunk_dir / f\"chunk_{i:05d}.wav\"\n",
    "    if not chunk_file.exists():\n",
    "        print(f\"[{i}/{total}] Synthesizing -> {chunk_file.name}\")\n",
    "        tts.tts_to_file(\n",
    "            text=chunk,\n",
    "            speaker_wav=str(voice_wav),\n",
    "            language=LANG,\n",
    "            file_path=str(chunk_file),\n",
    "        )\n",
    "    else:\n",
    "        print(f\"[{i}/{total}] Skipping existing -> {chunk_file.name}\")\n",
    "    chunk_files.append(chunk_file)\n",
    "\n",
    "print(f\"Generated {len(chunk_files)} chunk WAV files in: {chunk_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23616ef",
   "metadata": {},
   "source": [
    "## 8) Export final audiobook (.wav or .mp3) with:\n",
    "- **Silence trimming** (leading/trailing) via `silenceremove`\n",
    "- **Speed control** (tempo only) via `atempo`\n",
    "- **Volume normalization** via `loudnorm`\n",
    "- **MP3 bitrate** via encoder settings\n",
    "\n",
    "All of these use **FFmpeg**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate chunk WAVs into one AudioSegment\n",
    "combined = AudioSegment.empty()\n",
    "\n",
    "for cf in chunk_files:\n",
    "    seg = AudioSegment.from_wav(cf)\n",
    "    combined += seg\n",
    "\n",
    "export_with_ffmpeg_filters(\n",
    "    audio=combined,\n",
    "    out_path=OUT_AUDIO,\n",
    "    speed=SPEED,\n",
    "    mp3_bitrate=MP3_BITRATE,\n",
    "    trim_silence=TRIM_SILENCE,\n",
    "    silence_threshold_db=SILENCE_THRESHOLD_DB,\n",
    "    silence_min_sec=SILENCE_MIN_SEC,\n",
    "    normalize_loudness=NORMALIZE_LOUDNESS,\n",
    "    loudnorm_I=LOUDNORM_I,\n",
    "    loudnorm_TP=LOUDNORM_TP,\n",
    "    loudnorm_LRA=LOUDNORM_LRA,\n",
    ")\n",
    "\n",
    "print(f\"Done: {OUT_AUDIO.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94c845",
   "metadata": {},
   "source": [
    "## 9) Optional: cleanup chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a212b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True if you want to delete intermediate chunks after a successful export.\n",
    "DELETE_CHUNKS = False\n",
    "\n",
    "if DELETE_CHUNKS:\n",
    "    for cf in chunk_files:\n",
    "        try:\n",
    "            cf.unlink()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not delete {cf.name}: {e}\")\n",
    "    try:\n",
    "        chunk_dir.rmdir()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not remove chunk dir: {e}\")\n",
    "    print(\"Cleanup complete.\")\n",
    "else:\n",
    "    print(f\"Keeping chunks in: {chunk_dir.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
