{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73694c4",
   "metadata": {},
   "source": [
    "# Audiobook Generator (XTTS v2 model) — Notebook\n",
    "\n",
    "This notebook generates an audiobook-style audio file from a **TXT** file using a **reference voice sample** (**MP3**) for speaker conditioning via **Coqui TTS (XTTS v2)**.\n",
    "\n",
    "**Folder assumption:** the reference voice MP3 and the input TXT are in the **same folder** as this notebook (or you can point to a different folder).\n",
    "\n",
    "**Ethics/safety:** Only generate a voice you own or have **explicit permission** to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee09617",
   "metadata": {},
   "source": [
    "## 0. Install the dependencies: \n",
    "- `coqui-tts` for XTTS v2\n",
    "- `ffmpeg` is required for MP3 I/O (conversion + final MP3 export)\n",
    "\n",
    "If you don't have FFmpeg installed:\n",
    "- Windows: install via `choco install ffmpeg` (Chocolatey) or download an official build (\"ffmpeg-7.1.1-full_build-shared.7z\") and add to PATH\n",
    "- macOS: `brew install ffmpeg`\n",
    "- Linux (Debian/Ubuntu): `sudo apt-get install ffmpeg`\n",
    "\n",
    "Then run: `pip install -r requirements.txt`\n",
    "\n",
    "or like me (Windows):\n",
    "\n",
    "```bash\n",
    "python -m venv audiogen\n",
    "audiogen/Scripts/activate\n",
    "pip install ipykernel, coqui-tts\n",
    "pip install \"transformers==5.0.0\"\n",
    "uv pip install torch torchaudio torchcodec --torch-backend=auto\n",
    "git clone https://github.com/idiap/coqui-ai-TTS\n",
    "cd coqui-ai-TTS\n",
    "uv pip install -e .[notebooks]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49316e63",
   "metadata": {},
   "source": [
    "## 1. Imports and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tts_models/multilingual/multi-dataset/xtts_v2', 'tts_models/multilingual/multi-dataset/xtts_v1.1', 'tts_models/multilingual/multi-dataset/your_tts', 'tts_models/multilingual/multi-dataset/bark', 'tts_models/bg/cv/vits', 'tts_models/cs/cv/vits', 'tts_models/da/cv/vits', 'tts_models/et/cv/vits', 'tts_models/ga/cv/vits', 'tts_models/en/ek1/tacotron2', 'tts_models/en/ljspeech/tacotron2-DDC', 'tts_models/en/ljspeech/tacotron2-DDC_ph', 'tts_models/en/ljspeech/glow-tts', 'tts_models/en/ljspeech/speedy-speech', 'tts_models/en/ljspeech/tacotron2-DCA', 'tts_models/en/ljspeech/vits', 'tts_models/en/ljspeech/vits--neon', 'tts_models/en/ljspeech/fast_pitch', 'tts_models/en/ljspeech/overflow', 'tts_models/en/ljspeech/neural_hmm', 'tts_models/en/vctk/vits', 'tts_models/en/vctk/fast_pitch', 'tts_models/en/sam/tacotron2-DCA', 'tts_models/en/blizzard2013/capacitron-t2-c50', 'tts_models/en/blizzard2013/capacitron-t2-c150_v2', 'tts_models/en/multi-dataset/tortoise-v2', 'tts_models/en/jenny/jenny', 'tts_models/es/mai/tacotron2-DDC', 'tts_models/es/css10/vits', 'tts_models/fr/mai/tacotron2-DDC', 'tts_models/fr/css10/vits', 'tts_models/uk/mai/glow-tts', 'tts_models/uk/mai/vits', 'tts_models/zh-CN/baker/tacotron2-DDC-GST', 'tts_models/nl/rdh/tacotron2-DDC', 'tts_models/nl/css10/vits', 'tts_models/de/thorsten/tacotron2-DCA', 'tts_models/de/thorsten/vits', 'tts_models/de/thorsten/tacotron2-DDC', 'tts_models/de/css10/vits-neon', 'tts_models/ja/kokoro/tacotron2-DDC', 'tts_models/tr/common-voice/glow-tts', 'tts_models/it/mai_female/glow-tts', 'tts_models/it/mai_female/vits', 'tts_models/it/mai_male/glow-tts', 'tts_models/it/mai_male/vits', 'tts_models/ewe/openbible/vits', 'tts_models/hau/openbible/vits', 'tts_models/lin/openbible/vits', 'tts_models/tw_akuapem/openbible/vits', 'tts_models/tw_asante/openbible/vits', 'tts_models/yor/openbible/vits', 'tts_models/hu/css10/vits', 'tts_models/el/cv/vits', 'tts_models/fi/css10/vits', 'tts_models/hr/cv/vits', 'tts_models/lt/cv/vits', 'tts_models/lv/cv/vits', 'tts_models/mt/cv/vits', 'tts_models/pl/mai_female/vits', 'tts_models/pt/cv/vits', 'tts_models/ro/cv/vits', 'tts_models/sk/cv/vits', 'tts_models/sl/cv/vits', 'tts_models/sv/cv/vits', 'tts_models/ca/custom/vits', 'tts_models/fa/custom/glow-tts', 'tts_models/fa/custom/vits-female', 'tts_models/bn/custom/vits-male', 'tts_models/bn/custom/vits-female', 'tts_models/be/common-voice/glow-tts', 'vocoder_models/universal/libri-tts/wavegrad', 'vocoder_models/universal/libri-tts/fullband-melgan', 'vocoder_models/en/ek1/wavegrad', 'vocoder_models/en/librispeech100/wavlm-hifigan', 'vocoder_models/en/librispeech100/wavlm-hifigan_prematched', 'vocoder_models/en/ljspeech/multiband-melgan', 'vocoder_models/en/ljspeech/hifigan_v2', 'vocoder_models/en/ljspeech/univnet', 'vocoder_models/en/blizzard2013/hifigan_v2', 'vocoder_models/en/vctk/hifigan_v2', 'vocoder_models/en/sam/hifigan_v2', 'vocoder_models/nl/mai/parallel-wavegan', 'vocoder_models/de/thorsten/wavegrad', 'vocoder_models/de/thorsten/fullband-melgan', 'vocoder_models/de/thorsten/hifigan_v1', 'vocoder_models/ja/kokoro/hifigan_v1', 'vocoder_models/uk/mai/multiband-melgan', 'vocoder_models/tr/common-voice/hifigan', 'vocoder_models/be/common-voice/hifigan', 'voice_conversion_models/multilingual/vctk/freevc24', 'voice_conversion_models/multilingual/multi-dataset/knnvc', 'voice_conversion_models/multilingual/multi-dataset/openvoice_v1', 'voice_conversion_models/multilingual/multi-dataset/openvoice_v2']\n"
     ]
    }
   ],
   "source": [
    "import os, re, torch\n",
    "from TTS.api import TTS\n",
    "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
    "\n",
    "# # Get device if NVDIA GPU is present. AMD GPU is not supported or very limit.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(TTS().list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903370e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the location of cached voice\n",
    "\n",
    "WORKDIR = os.getcwd()\n",
    "if (\"XDG_DATA_HOME\" not in os.environ) and (\"TTS_HOME\" not in os.environ):\n",
    "\tos.environ[\"XDG_DATA_HOME\"] = WORKDIR + \"\\\\temp\"\n",
    "\tos.environ[\"TTS_HOME\"] = WORKDIR + \"\\\\temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8764292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THOUGHT OUT THOUGHT', 'Thoughts are not you. They are not yours to believe, not yours to follow, not even for you to be drawn near. Thought is a natural process—it appears, and it passes. So thought is not you, not for you, not happening to you, nor even against you. Only ignorance can blinds you from noticing this fact.', 'For many of us, the opposite seems true. In fact, thoughts can be so real that we cannot dispute or oppose them. Take the case of regret over a deed wrongly done— or not done when it should have been. Or worry over what may happen in the future. Such thoughts can feel so real that, in extreme cases, they drive a person to take their own life, or even act in revenge.', 'In ordinary daily life, even a single passing thought—such as judging another—can make us believe in it entirely. If such small thoughts have this much sway, how much more powerful the severe and extreme ones?', 'Certain thoughts may be trivial or unfounded, yet they can still cause stress—like forgetting an umbrella during a rainy season and worrying over it. We may laugh at such concerns, but if we were in their shoes, we would not see it as absurd.', 'As I pen this article, I am being reminded of the countless occasions when I myself have fallen into this trap out of ignorance—and how I still do so many times throughout the day when I am not mindful of its nature. To come out of the snare of thoughts, we do not fight them nor believe them—we train in seeing them as they are—fleeting, impersonal, and not ours to own.', 'SEEING PROCESSES AS PROCESSES', 'There are many ways to notice thoughts correctly, rather than being identified with them. Awareness—mindfulness—is indispensable in this process. Without it, we are easily swept away.', 'Mind processes, or even bodily processes, are not entities at all. They are processes—ongoing happenings with no inherent self or essence hidden within them. This is a fundamental view, a grounding for practice.', 'Even consciousness is not a sentient entity. It is simply the act of knowing—just as fire has the function of burning, yet no “fireself” within it. To see this is to train in viewing mind as nature, not as self.', 'The same is true of feeling. Feeling is simply feeling—suchness arising and passing, like a breeze that touches the skin and moves on. It is impersonal. To see it in this way is not a trick of suggestion, nor a philosophy to adopt, but a matter of fact. For so long it has been mistaken as “me,” “mine,” or “myself,” yet in truth it has always been nothing more than nature unfolding.', 'In overturning the errors of mistaken mental processes as a being, much work needs to be done, requiring awareness of their realities.', 'OBSERVING THOUGHT IN PRACTICE', 'Can you notice that a thought is just a process? Within it, juicy narratives may arise—but these are merely stories. It is like reading a novel: no matter how suspenseful or heartbreaking it is, in the background of your immersion, you remain aware it is not real. Frame your mind from this perspective, and identification with thought may loosen. To observe from this angle, train yourself to see thought as no more than a redundant echo, a passing shout, or an elusive formation.', 'Remember: identification arises only from a wrong way of taking what is unreal as real. Correct understanding is enough to dissolve it.', 'Another way to see thought correctly is to remember that prior to its arising, it did not exist. All thoughts reference some kind of happening—present, past, or future. The past is gone; the future has not yet arisen; to dwell on', 'them is merely an imaginative mismatch.', 'But what about the present moment? The present unfolds independently of how we think about it. If we meet it as it is, the happening has no more or less to it—it simply expresses its own suchness. When we overlay meaning onto it, however, ideas impose upon the actual happening rather than the happening itself. This is what is meant by “thoughtout”—more like a shout over reality. Prior to the thought, during the thought, and after the thought—what difference is there? Thought is not reality itself, but a processed overlay of it.', 'It is like saying that where you are standing with your thoughts is not the same as the reality they point to. One example is seeing a product through a shop window is not the same as experiencing the product itself. The image,', 'reflection, or partial view may entice or mislead, but it is never the full reality. Likewise, thoughts provide a representation, a story, a narrative, a fabrication—but they are not the reality itself.', 'In this way, you can see thought as an independent object of occurrence, separate from the actual happening, rather than mistaking it for reality itself.', 'THE EMPTY NATURE OF MENTAL PHENOMENA', 'Another angle in observing thought is recognizing its inherently empty nature. This requires a deeper understanding of all mental phenomena, not just thought alone. The nature of all mental phenomena is empty—they are devoid of substantial existence. Why? Because they are simply processes that come and go, rather than something permanent or unchanging. Anything that does not last cannot be substantial, and what is not substantial is, in its ultimate sense, empty.', 'Another way to put it is that mental states, at any given moment, are nothing more than fleeting expressions of experience. They function only as long as they arise, and disappear completely when they pass.', 'They are not hidden, stored, or parked elsewhere awaiting the next round. When they are gone, they do not exist at all—until the next condition gives rise to them.', 'A COURSE IN MIRACLES goes further by challenging us with this definitive view: what is real cannot be threatened; what is unreal does not exist. Anything that can be threatened does not truly exist. This is profound, considering that', 'everything in existence is constantly being threatened by change, driven by the law of cause and effect, and therefore does not truly exist, or even exist at all.', 'Thus, all so-called “existential” things exist only as illusory fabrications of appearances— including the idea of self. For one not yet skillful in noticing thought, this understanding can be challenging. Yet it is valuable', 'knowledge to revisit as one matures in the understanding of the mind. Only then does the insight that “the world does not exist”—a reality that is merely a projection of the mind—become deeply apparent.', 'PRACTICE WITH THOUGHT', 'In practice, thought is not to be removed—for to attempt removal is already to treat it as real. The true practice is simply to see its transient nature. A thought comes, and it goes. It leaves no trace except the one we carve into it', 'through attachment. To meet it in this way is to neither cling to thought nor push it away, but to let it be known as it is: a passing occurrence, not a possession, not a self.', 'To see thoughts as processes, to observe their empty nature, is to begin loosening the grip of delusion. What once appeared as “me” is revealed as no more than passing appearances—arising, shaping themselves for a while, then dissolving back into emptiness.', 'In truth, nothing in thought can bind you; only ignorance makes it seem so. When awareness is steady, thought is simply known as thought, and reality is met as it is. In that moment, the burden of “self” lifts, and what remains is', 'clarity, freedom, and peace.', 'Ignorance, coupled with attachment, makes thought appear real. With Right Understanding, both ignorance and attachment fall away, and thoughts simply fade—without needing to do anything with them.', 'This is the only way']\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    # Remove hyphenation at line breaks: \"exam-\\nple\" -> \"example\"\n",
    "    text = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", text)\n",
    "    # Collapse whitespace\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "file_path = 'thought out thought.txt'\n",
    "contents = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        if line.strip():\n",
    "            contents.append(normalize_text(line))\n",
    "\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d03731",
   "metadata": {},
   "source": [
    "## 2. Provide reference audio files and generate a sample simple speech with that voice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22727b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab09b66e8f854643a9a95b6bb7c3bbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b8f2f984414e2ca1213d33f16eb16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize TTS model\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "\n",
    "# reference audio\n",
    "reference_files = [\"reference_voice.mp3\"]\n",
    "tts.tts_to_file(\n",
    "    text=contents[0],\n",
    "    speaker_wav=reference_files,\n",
    "    language=\"en\",\n",
    "    file_path=\"output.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47fa5d",
   "metadata": {},
   "source": [
    "## 3. Cache reference voices for easy reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713a0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.tts_to_file(\n",
    "  text=contents[6],\n",
    "  speaker_wav=reference_files,\n",
    "  speaker=\"HorTuckLoon\",\n",
    "  language=\"en\",\n",
    "  file_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "26c7497d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.tts_to_file(\n",
    "  text=contents[0],\n",
    "  speaker=\"HorTuckLoon\",\n",
    "  language=\"en\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
